# ğŸ“š StorytimeTTS - AI-Powered Audiobook Generation Platform

Transform text content into high-quality audiobooks with intelligent processing! StorytimeTTS has evolved into a streamlined, unified job management platform supporting both simple text-to-audio conversion and intelligent book processing with automatic chapter detection.

## ğŸŒŸ Current Features

- **ğŸ¯ Unified Job Management**: Single API for all audiobook processing types
- **ğŸ“– Intelligent Book Processing**: Automatic chapter detection and structure analysis
- **ğŸ”„ Resume Functionality**: Chapter-level progress tracking for long-form content
- **ğŸ™ï¸ Multi-Provider TTS**: OpenAI and ElevenLabs voice synthesis
- **ğŸ”’ Secure Storage**: Private file storage with DigitalOcean Spaces
- **âš¡ Background Processing**: Scalable Celery-based job execution
- **ğŸ“Š Progress Tracking**: Real-time job status and step-by-step monitoring

## ğŸ—ï¸ System Architecture

### **REST API Endpoints**
```
/api/v1/jobs/          - Complete job lifecycle management
/api/v1/audio/         - Audio streaming with resume support
/api/v1/progress/      - Playback progress and resume functionality
/api/v1/auth/          - JWT-based authentication
```

### **Processing Workflows**
```
Simple Text â†’ Job Creation â†’ TTS Processing â†’ Audio Output â†’ Secure Storage

Book Processing â†’ Chapter Detection â†’ Parallel Processing â†’ Audio Generation â†’ Result Aggregation

```

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone repository
git clone <repository-url>
cd storytime

# Install dependencies (preferred method)
uv sync

# Alternative installation
pip install -e .
```

### 2. Required Services

- **PostgreSQL**: Database for job and user management
- **Redis**: Task queue for background processing
- **DigitalOcean Spaces**: File storage (or AWS S3 compatible)

### 3. Environment Variables

```bash
# Database
export DATABASE_URL="postgresql://user:pass@localhost/storytime"

# AI Services
export OPENAI_API_KEY="your_openai_api_key"
export ELEVENLABS_API_KEY="your_elevenlabs_api_key"  # Optional

# File Storage
export DO_SPACES_KEY="your_spaces_access_key"
export DO_SPACES_SECRET="your_spaces_secret_key"
export DO_SPACES_ENDPOINT="your_spaces_endpoint"
export DO_SPACES_BUCKET="your_bucket_name"

# Authentication
export JWT_SECRET_KEY="your_jwt_secret_key"

# Background Processing
export CELERY_BROKER_URL="redis://localhost:6379/0"

# Optional Configuration
export TTS_PROVIDER="openai"  # or "eleven"
```

When using `docker-compose`, the tool will automatically load variables from a
`.env` file if one exists. Any environment variables set in your shell take
precedence over values from that file.

### 4. Start the Application

```bash
# Start the FastAPI server
cd src && python -m storytime.api.main

# Or with uvicorn directly
uvicorn storytime.api.main:app --reload --host 0.0.0.0 --port 8000

# Start Celery worker (separate terminal)
celery -A storytime.worker.celery_app worker --loglevel=info

# Build and start React client (separate terminal)
cd client && npm install && npm run dev
```

### 5. Run Tests

```bash
# Run all tests
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ --cov=src/storytime

# Code quality checks
ruff check .
ruff format .
```

## ğŸ“‹ Core Components

### **ğŸ¯ Unified Job System**
- **Job Types**: TEXT_TO_AUDIO, BOOK_PROCESSING
- **Step Tracking**: Granular progress monitoring with detailed error handling
- **Resume Support**: Chapter-level progress for long-form content

### **ğŸ“– Book Intelligence**
- **Chapter Detection**: Multiple strategies (numbered, roman numerals, content-based)
- **Content Analysis**: Automatic structure recognition for various book formats
- **Parallel Processing**: Concurrent chapter processing for faster results

### **ğŸ™ï¸ TTS Processing**
- **Smart Chunking**: Respects API limits with sentence/word boundary splitting
- **Voice Selection**: Configurable voice assignment per provider
- **Audio Concatenation**: Seamless stitching of audio segments

### **ğŸ”’ Secure Infrastructure**
- **Private Storage**: All files stored with private ACL for security
- **JWT Authentication**: Secure user session management
- **Pre-signed URLs**: Temporary access for downloads and streaming

## ğŸ­ Supported Job Types

### **1. Simple Text-to-Audio**
```python
{
    "job_type": "TEXT_TO_AUDIO",
    "text": "Your text content here...",
    "voice_config": {
        "provider": "openai",
        "voice": "nova"
    }
}
```

### **2. Book Processing**
```python
{
    "job_type": "BOOK_PROCESSING",
    "text": "Full book content...",
    "processing_config": {
        "max_concurrency": 4
    }
}
```


## ğŸ“Š API Usage Examples

### **Create a Job**
```bash
curl -X POST "http://localhost:8000/api/v1/jobs/" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer YOUR_JWT_TOKEN" \
     -d '{
       "job_type": "TEXT_TO_AUDIO",
       "text": "Hello, this is a test of the text-to-speech system.",
       "voice_config": {
         "provider": "openai",
         "voice": "nova"
       }
     }'
```

### **Check Job Status**
```bash
curl "http://localhost:8000/api/v1/jobs/{job_id}" \
     -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

### **Stream Audio**
```bash
curl "http://localhost:8000/api/v1/audio/{job_id}/stream" \
     -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

### **Update Progress**
```bash
curl -X PUT "http://localhost:8000/api/v1/progress/{job_id}" \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer YOUR_JWT_TOKEN" \
     -d '{
       "position": 120.5,
       "chapter": 1
     }'
```

## ğŸ“ Output Structure

```
digitalocean_spaces/
â”œâ”€â”€ jobs/{job_id}/
â”‚   â”œâ”€â”€ input.txt              (Original text)
â”‚   â”œâ”€â”€ result.json            (Processing metadata)
â”‚   â””â”€â”€ output.mp3             (Final audio)
â”œâ”€â”€ chapters/{job_id}/
â”‚   â”œâ”€â”€ chapter_01.mp3         (Individual chapters)
â”‚   â”œâ”€â”€ chapter_02.mp3
â”‚   â””â”€â”€ playlist.m3u           (M3U playlist)
â””â”€â”€ temp/
    â””â”€â”€ processing_files/      (Temporary processing files)
```

## ğŸ”§ Development

### **Database Migrations**
```bash
# Create migration
alembic revision --autogenerate -m "Description"

# Apply migrations
alembic upgrade head
```

### **Docker Development**
```bash
# Build and run with docker-compose
docker-compose up --build

# Run individual container
docker build -t storytime .
docker run -p 8000:8000 storytime
```

### **Code Quality**
```bash
# Lint and format
ruff check .
ruff format .

# Type checking
mypy src/
```

## ğŸ’° Cost Estimates

### **OpenAI TTS**
- **Rate**: $0.015 per 1,000 characters
- **Average chapter**: ~$0.50-2.00
- **Full novel**: ~$50-200

### **ElevenLabs TTS**
- **Rate**: Varies by plan and usage
- **Character limits**: Plan-dependent
- **Voice cloning**: Premium feature

### **Infrastructure**
- **DigitalOcean Spaces**: $5/month + transfer costs
- **Database**: $15-50/month depending on size
- **Redis**: $15-25/month for managed service

## ğŸ› Troubleshooting

### **Common Issues**

1. **Database Connection Errors**
   ```bash
   # Check database connection
   psql $DATABASE_URL

   # Run migrations
   alembic upgrade head
   ```

2. **Celery Worker Issues**
   ```bash
   # Check Redis connection
   redis-cli ping

   # Restart worker
   celery -A storytime.worker.celery_app worker --loglevel=debug
   ```

3. **File Storage Issues**
   ```bash
   # Test DigitalOcean Spaces connection
   python - <<'PY'
   import asyncio
   from storytime.infrastructure.spaces import SpacesClient

   async def main():
       client = SpacesClient()
       url = await client.get_presigned_download_url('test-key')
       print('Connected')

   asyncio.run(main())
   PY
   ```

4. **TTS Provider Errors**
   - Verify API keys are valid
   - Check rate limits and quotas
   - Monitor character usage

## ğŸ“Š Monitoring & Observability

### **Job Tracking**
- Real-time job status updates
- Step-by-step progress monitoring
- Detailed error reporting and logging

### **Performance Metrics**
- Processing time per job type
- TTS provider usage statistics
- Database query performance

### **Error Handling**
- Automatic retry logic with exponential backoff
- Graceful degradation for provider outages
- Comprehensive error logging

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add tests for new functionality
5. Run the test suite (`pytest tests/`)
6. Commit your changes (`git commit -m 'Add amazing feature'`)
7. Push to the branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- **OpenAI** for high-quality text-to-speech services
- **ElevenLabs** for advanced voice synthesis capabilities
- **FastAPI** for the excellent async web framework
- **Pydantic** for type-safe data validation
- **SQLAlchemy** for robust database operations
- **Celery** for reliable background job processing

---

**Ready to transform text into engaging audiobooks? Start with the API at `http://localhost:8000/docs`!** ğŸ§ğŸ“š

## ğŸš§ Recent Updates

- âœ… **CORE-49**: Implemented playback progress tracking with resume functionality
- âœ… **CORE-55**: Enhanced security with private ACL for all file uploads
- âœ… **CORE-50**: Added audio streaming API with resume support
- âœ… **CORE-54**: Completed legacy dependency cleanup and modernization
- âœ… **Unified Job System**: Streamlined all processing through single job management API
- âœ… **Book Intelligence**: Added automatic chapter detection and parallel processing
- âœ… **Background Processing**: Implemented scalable Celery-based job execution
- âœ… **Environment-Based Features**: Added feature flags system with conditional user registration

For detailed development guidance, see [CLAUDE.md](CLAUDE.md)

## ğŸ” Environment-Based Features

StorytimeTTS now includes environment-aware feature flags:

### **Feature Flag System**
- **Endpoint**: `/api/v1/environment` returns current environment and feature flags
- **User Registration**: Automatically enabled in `dev` and `docker` environments, disabled in `production`
- **Extensible**: Easy to add new feature flags for A/B testing or gradual rollouts

### **Environment Detection**
```javascript
// Client-side usage
import { getEnvironment } from './utils/environment';

const env = await getEnvironment();
if (env.features.signup_enabled) {
  // Show registration UI
}
```

### **Current Feature Flags**
- `signup_enabled`: Controls new user registration (true for dev/docker, false for production)
- `debug_mode`: Enables debug features (true for dev only)
- `demo_mode`: Reserved for future demo functionality

### **Configuration**
Set the environment via the `ENV` variable:
- `ENV=dev` - Local development (signup enabled)
- `ENV=docker` - Docker Compose (signup enabled)
- `ENV=production` - Production deployment (signup disabled)
